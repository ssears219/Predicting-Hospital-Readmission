{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Sensitive Random Forest using CostCla  \n",
    "\n",
    "In this notebook a cost sensitive learning approach was used to attempt to optimize the training of the model by considering actual costs for False Positives and False Negatives. We found that the CostCla package allowed for a cost matrix as an input parameter and our hopes were that this would minimize resulting cost of predictions.\n",
    "\n",
    "Documentation: https://albahnsen.github.io/CostSensitiveClassification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Modeling Preparation  \n",
    "\n",
    "The same data preprocessing and model preparation steps were taken for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('dataset_diabetes/diabetic_data.csv', na_values = '?')\n",
    "\n",
    "def convert_code(code):\n",
    "    try:\n",
    "        code = float(code)\n",
    "        if code >= 1 and code <= 139:\n",
    "            return 1\n",
    "        elif code >= 140 and code <= 239:\n",
    "            return 2\n",
    "        elif code >= 240 and code <= 279:\n",
    "            return 3\n",
    "        elif code >= 280 and code <= 289:\n",
    "            return 4\n",
    "        elif code >= 290 and code <= 319:\n",
    "            return 5\n",
    "        elif code >= 320 and code <= 389:\n",
    "            return 6\n",
    "        elif code >= 390 and code <= 459:\n",
    "            return 7\n",
    "        elif code >= 460 and code <= 519:\n",
    "            return 8\n",
    "        elif code >= 520 and code <= 579:\n",
    "            return 9\n",
    "        elif code >= 580 and code <= 629:\n",
    "            return 10\n",
    "        elif code >= 630 and code <= 679:\n",
    "            return 11\n",
    "        elif code >= 680 and code <= 709:\n",
    "            return 12\n",
    "        elif code >= 710 and code <= 739:\n",
    "            return 13\n",
    "        elif code >= 740 and code <= 759:\n",
    "            return 14\n",
    "        elif code >= 760 and code <= 779:\n",
    "            return 15\n",
    "        elif code >= 780 and code <= 799:\n",
    "            return 16\n",
    "        elif code >= 800 and code <= 999:\n",
    "            return 17\n",
    "    except:\n",
    "        if 'V' in code:\n",
    "            return 18\n",
    "        elif 'E' in code:\n",
    "            return 19\n",
    "        else:\n",
    "            return 'Code not mapped'\n",
    "\n",
    "data['diag_1_mapped'] = data.diag_1.apply(convert_code)\n",
    "data['diag_2_mapped'] = data.diag_2.apply(convert_code)\n",
    "data['diag_3_mapped'] = data.diag_3.apply(convert_code)\n",
    "\n",
    "data = data.loc[~data.discharge_disposition_id.isin([11,13,14,18,20,21])]\n",
    "\n",
    "data['Target_Label'] = (data.readmitted == '<30').astype(int)\n",
    "\n",
    "num_col_names = ['time_in_hospital','num_lab_procedures', 'num_procedures', 'num_medications',\\\n",
    "                 'number_outpatient', 'number_emergency', 'number_inpatient','number_diagnoses']\n",
    "\n",
    "cat_col_names = ['race', 'gender', 'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide',\\\n",
    "                 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide',\\\n",
    "                 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose',\\\n",
    "                 'miglitol', 'troglitazone','tolazamide', 'insulin', 'glyburide-metformin',\\\n",
    "                 'glipizide-metformin','glimepiride-pioglitazone', 'metformin-rosiglitazone',\\\n",
    "                 'metformin-pioglitazone', 'change', 'diabetesMed','payer_code']\n",
    "\n",
    "# Fill NA with 'UNK'\n",
    "data['race'] = data['race'].fillna('UNK')\n",
    "data['payer_code'] = data['payer_code'].fillna('UNK')\n",
    "data['medical_specialty'] = data['medical_specialty'].fillna('UNK')\n",
    "data['diag_1_mapped'] = data['diag_1_mapped'].fillna('UNK')\n",
    "data['diag_2_mapped'] = data['diag_2_mapped'].fillna('UNK')\n",
    "data['diag_3_mapped'] = data['diag_3_mapped'].fillna('UNK')\n",
    "\n",
    "# Get top 10 medical specialties\n",
    "top_10_spec = list(data['medical_specialty'].value_counts(dropna=False)[0:10].index)\n",
    "\n",
    "# New medical_specialty column\n",
    "data['med_spec_new'] = data['medical_specialty'].copy()\n",
    "\n",
    "# Replace values with 'Other' if not in Top 10\n",
    "data.loc[~data.med_spec_new.isin(top_10_spec), 'med_spec_new'] = 'Other'\n",
    "\n",
    "# Convert Numerical Categorical Columns to strings\n",
    "cat_col_num = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id',\\\n",
    "               'diag_1_mapped', 'diag_2_mapped', 'diag_3_mapped']\n",
    "data[cat_col_num] = data[cat_col_num].astype(str)\n",
    "\n",
    "# Create Categorical Predictors DataFrame\n",
    "data_cat = pd.get_dummies(data[cat_col_names + cat_col_num + ['med_spec_new']], drop_first = True)\n",
    "\n",
    "# Add Categorical Predictor Variables to main DataFrame\n",
    "data = pd.concat([data, data_cat], axis = 1)\n",
    "\n",
    "# Retain columns of data_cat\n",
    "data_cat_cols = list(data_cat.columns)\n",
    "\n",
    "# Create Age Group Variable\n",
    "age_dict = {'[0-10)':0, \n",
    "            '[10-20)':10, \n",
    "            '[20-30)':20, \n",
    "            '[30-40)':30, \n",
    "            '[40-50)':40, \n",
    "            '[50-60)':50,\n",
    "            '[60-70)':60, \n",
    "            '[70-80)':70, \n",
    "            '[80-90)':80, \n",
    "            '[90-100)':90}\n",
    "data['age_group'] = data.age.replace(age_dict)\n",
    "\n",
    "# Create Age Variable\n",
    "data['has_weight'] = data.weight.notnull().astype('int')\n",
    "\n",
    "# Save feature names\n",
    "features = ['age_group', 'has_weight']\n",
    "\n",
    "# Dataframe for modeling\n",
    "model_data = data[num_col_names + data_cat_cols + features + ['Target_Label']]\n",
    "\n",
    "# Shuffle Data\n",
    "model_data = model_data.sample(n=len(model_data),random_state=10)\n",
    "model_data = model_data.reset_index(drop=True)\n",
    "\n",
    "# 15% Validation / 15% Test split / 70% Train\n",
    "vd_test = model_data.sample(frac=0.3, random_state=10)\n",
    "test_data = vd_test.sample(frac=0.5, random_state=10)\n",
    "vd_data = vd_test.drop(test_data.index)\n",
    "train_data = model_data.drop(vd_test.index)\n",
    "\n",
    "# Split training data into positive and negative\n",
    "positive = train_data.Target_Label == 1\n",
    "train_data_pos = train_data.loc[positive]\n",
    "train_data_neg = train_data.loc[~positive]\n",
    "\n",
    "# Merge and Balance\n",
    "train_data_balanced = pd.concat([train_data_pos, train_data_neg.sample(n = len(train_data_pos), random_state=10)], axis = 0)\n",
    "\n",
    "# Shuffle\n",
    "train_data_balanced = train_data_balanced.sample(n = len(train_data_balanced), random_state = 10).reset_index(drop=True)\n",
    "\n",
    "train_matrix = train_data[num_col_names + data_cat_cols + features].values\n",
    "train_balanced_matrix = train_data_balanced[num_col_names + data_cat_cols + features].values\n",
    "vd_matrix = vd_data[num_col_names + data_cat_cols + features].values\n",
    "\n",
    "train_labels = train_data_balanced['Target_Label'].values\n",
    "vd_labels = vd_data['Target_Label'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_matrix)\n",
    "\n",
    "scaled_train = scaler.transform(train_balanced_matrix)\n",
    "scaled_vd = scaler.transform(vd_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(actual, predicted):\n",
    "    AUC = roc_auc_score(actual, predicted)\n",
    "    accuracy = accuracy_score(actual, predicted)\n",
    "    precision = precision_score(actual, predicted)\n",
    "    recall = recall_score(actual, predicted)\n",
    "    conf_matrix = confusion_matrix(actual, predicted)\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in conf_matrix.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in conf_matrix.flatten()/np.sum(conf_matrix)]\n",
    "    cost = ((int(group_counts[1])*1780)+(int(group_counts[2])*14400))/len(actual)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Sensitive Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from costcla.models import CostSensitiveRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ssear\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cost = []\n",
    "fp = []\n",
    "fn = []\n",
    "for i in range(1, 50, 5):\n",
    "    for j in range(1, 50, 5):\n",
    "        cost_matrix = np.array([[i, j, 0, 0]])\n",
    "        for k in range(len(train_labels)-1):\n",
    "            cost_matrix = np.append(cost_matrix, [[i, j, 0, 0]], axis=0)\n",
    "        CSRandomForest = CostSensitiveRandomForestClassifier()\n",
    "        CSRandomForest.fit(scaled_train, train_labels, cost_matrix)\n",
    "        vd_predictions = CSRandomForest.predict_proba(scaled_vd)[:,1]\n",
    "        vd_predictions[vd_predictions > 0.50] = 1\n",
    "        vd_predictions[vd_predictions <= 0.50] = 0\n",
    "        cost.append(report(vd_labels, vd_predictions))\n",
    "        fp.append(i)\n",
    "        fn.append(j)\n",
    "        \n",
    "cost_df = pd.DataFrame({'FP': fp, 'FN': fn, 'Cost': cost})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1262.185518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1263.005087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>41</td>\n",
       "      <td>46</td>\n",
       "      <td>1269.196460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1271.999442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>1277.885567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1691.992473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>1692.116524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>21</td>\n",
       "      <td>41</td>\n",
       "      <td>1692.951425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>1693.695728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>1695.174577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FP  FN         Cost\n",
       "11   6   6  1262.185518\n",
       "33  16  16  1263.005087\n",
       "89  41  46  1269.196460\n",
       "0    1   1  1271.999442\n",
       "78  36  41  1277.885567\n",
       "..  ..  ..          ...\n",
       "80  41   1  1691.992473\n",
       "38  16  41  1692.116524\n",
       "48  21  41  1692.951425\n",
       "58  26  41  1693.695728\n",
       "36  16  31  1695.174577\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_df.sort_values(by='Cost', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: The CostCla package was useful in that it allowed for the utilization of a cost matrix. However, after further research, it was discovered the algorithm was made primarily for observation dependent cost matricies. In otherwords, the costs for misclassifications would be different depending on the feature values. The way we implemented it here was to use a constant cost matrix and check the effects of using different cost proportions for FP and FN in training. As a result, the parameters that produced the lowest cost model still did not perform better than previous models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
